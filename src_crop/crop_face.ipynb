{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "\n",
    "from landmarks.landmarks_extraction import load_images_bgr, Video_preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (658, 492)\n",
    "crop_size = (300, 300)\n",
    "\n",
    "\n",
    "crop_margin = np.array(crop_size)//2\n",
    "\n",
    "\n",
    "def create_img_crop(img,lm):\n",
    "    max_p = np.max(lm,axis=0)\n",
    "    min_p = np.min(lm,axis=0)\n",
    "    center = min_p + (max_p-min_p)//2\n",
    "    p_up = center-crop_margin\n",
    "    p_down = center+crop_margin\n",
    "\n",
    "\n",
    "    # set margin\n",
    "    if p_up[0] < 0:\n",
    "        p_down[0] -= p_up[0]\n",
    "        p_up[0] = 0\n",
    "    if p_up[1] < 0:\n",
    "        p_down[1] -= p_up[1]\n",
    "        p_up[1] = 0 \n",
    "    if p_down[0] > img_size[0]:\n",
    "        p_up[0] -= p_down[0] - img_size[0]\n",
    "        p_down[0] = img_size[0]\n",
    "    if p_down[1] > img_size[1]:\n",
    "        p_up[1] -= p_down[1] - img_size[1]\n",
    "        p_down[1] = img_size[1]\n",
    "\n",
    "\n",
    "    return img[p_up[1]:p_down[1],p_up[0]:p_down[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_castphys = Path(\"D:/TFG_ALEX/castphys_60\")\n",
    "save_folder = Path(\"D:/TFG_ALEX/castphys_crop\")\n",
    "\n",
    "options = {}\n",
    "preprocessing = Video_preprocessing(options)\n",
    "fps = 60\n",
    "\n",
    "ids = [int(patient.split('_')[1]) for patient in glob(\"Patient_*\", root_dir=folder_castphys)]\n",
    "id = ids[0]\n",
    "Patient_path = folder_castphys/ f\"Patient_{id}\"\n",
    "list_videos = glob(\"Q*\",root_dir=Patient_path)# + glob(\"E*\",root_dir=Patient_path)\n",
    "v_name = list_videos[0]\n",
    "img_path = Patient_path / v_name / \"imgs\"\n",
    "\n",
    "\n",
    "video = load_images_bgr(img_path, [])\n",
    "pred_landmarks = preprocessing.landmarks_extraction(video)\n",
    "\n",
    "\n",
    "video_crop = [create_img_crop(frm,lm) for frm, lm in zip(video,pred_landmarks)]\n",
    "\n",
    "\n",
    "video_save = cv2.VideoWriter(str(save_folder / f\"video_{id}_{v_name}_full.mp4\"),\n",
    "                             cv2.VideoWriter_fourcc(*'mp4v'),fps,crop_size)\n",
    "for i in range(0,len(video_crop)): #6\n",
    "    video_save.write(video_crop[i])\n",
    "video_save.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (658, 492)\n",
    "crop_size = (300, 300)\n",
    "sr = (30,30) # Smoothing range\n",
    "\n",
    "crop_margin = np.array(crop_size)//2\n",
    "\n",
    "\n",
    "def create_img_crop_smoot(img,center_list):\n",
    "    center = np.mean(center_list,axis=0,dtype=int)\n",
    "    p_up = center-crop_margin\n",
    "    p_down = center+crop_margin\n",
    "\n",
    "\n",
    "    # set margin\n",
    "    if p_up[0] < 0:\n",
    "        p_down[0] -= p_up[0]\n",
    "        p_up[0] = 0\n",
    "    if p_up[1] < 0:\n",
    "        p_down[1] -= p_up[1]\n",
    "        p_up[1] = 0 \n",
    "    if p_down[0] > img_size[0]:\n",
    "        p_up[0] -= p_down[0] - img_size[0]\n",
    "        p_down[0] = img_size[0]\n",
    "    if p_down[1] > img_size[1]:\n",
    "        p_up[1] -= p_down[1] - img_size[1]\n",
    "        p_down[1] = img_size[1]\n",
    "\n",
    "\n",
    "    return img[p_up[1]:p_down[1],p_up[0]:p_down[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_castphys = Path(\"D:/TFG_ALEX/castphys_60\")\n",
    "save_folder = Path(\"D:/TFG_ALEX/castphys_crop\")\n",
    "\n",
    "options = {}\n",
    "preprocessing = Video_preprocessing(options)\n",
    "\n",
    "fps = 60\n",
    "\n",
    "\n",
    "ids = [int(patient.split('_')[1]) for patient in glob(\"Patient_*\", root_dir=folder_castphys)]\n",
    "id = ids[0]\n",
    "Patient_path = folder_castphys/ f\"Patient_{id}\"\n",
    "list_videos = glob(\"Q*\",root_dir=Patient_path)# + glob(\"E*\",root_dir=Patient_path)\n",
    "v_name = list_videos[0]\n",
    "img_path = Patient_path / v_name / \"imgs\"\n",
    "\n",
    "video = load_images_bgr(img_path, [])\n",
    "pred_landmarks = preprocessing.landmarks_extraction(video)\n",
    "\n",
    "center_list = [np.min(lm,axis=0) + (np.max(lm,axis=0)-np.min(lm,axis=0))//2 for lm in pred_landmarks]\n",
    "\n",
    "video_crop = [create_img_crop_smoot(frm,center_list[id-sr[0] if id-sr[0]>=0 else 0:id+sr[1]]) \n",
    "              for id, frm in enumerate(video)]\n",
    "\n",
    "video_save = cv2.VideoWriter(str(save_folder / f\"video_{id}_{v_name}_s.mp4\"),\n",
    "                             cv2.VideoWriter_fourcc(*'mp4v'),fps,crop_size)\n",
    "for i in range(0,len(video_crop)): #6\n",
    "    video_save.write(video_crop[i])\n",
    "video_save.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Static"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([428, 335])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_crop = Path(\"D:/TFG_ALEX/crop\")\n",
    "img_size = (658, 492)\n",
    "\n",
    "def transform_column(df, col):\n",
    "    return [[int(''.join(i[:-1])[1:]),int(i[-1][:-1])] for i in [e.split(' ') for e in df[col]]]\n",
    "\n",
    "ids = [int(file.split('.')[0].split('_')[-1]) for file in glob(\"crop_lm_*\", root_dir=folder_crop)]\n",
    "ids.sort()\n",
    "\n",
    "#id = ids[0]\n",
    "max_all_size = []\n",
    "for id in ids:\n",
    "    df = pd.read_csv(folder_crop / f\"crop_lm_{id}.csv\")\n",
    "\n",
    "    df['r_size'] = transform_column(df, 'r_size')\n",
    "    df['p_up'] = transform_column(df, 'p_up')\n",
    "    df['p_down'] = transform_column(df, 'p_down')\n",
    "    #df['d_down'] = transform_column(df, 'd_down') ## Esta mal\n",
    "    df.columns = [\"video\", \"r_size\", \"p_up\", \"p_down\", \"d_down\"]\n",
    "\n",
    "    #max_r_size = [[(x_down)-x_up,(y_down)-y_up] \n",
    "    #               for [x_up,y_up],[x_down,y_down] in zip(df['p_up'],df['p_down'])]\n",
    "    max_r_size = [[(x_down if x_down<img_size[0] else img_size[0])-x_up,\n",
    "                   (y_down if y_down<img_size[1] else img_size[1])-y_up] \n",
    "                   for [x_up,y_up],[x_down,y_down] in zip(df['p_up'],df['p_down'])]\n",
    "    max_all_size.append(np.max(max_r_size, axis=0))\n",
    "\n",
    "#max_all_size\n",
    "np.max(max_all_size, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (658, 492)\n",
    "crop_size = (450, 350)\n",
    "\n",
    "crop_margin = np.array(crop_size)//2\n",
    "\n",
    "\n",
    "def search_margin_static(center):\n",
    "    p_up = center-crop_margin\n",
    "    p_down = center+crop_margin\n",
    "\n",
    "    # set margin\n",
    "    if p_up[0] < 0:\n",
    "        p_down[0] -= p_up[0]\n",
    "        p_up[0] = 0\n",
    "    if p_up[1] < 0:\n",
    "        p_down[1] -= p_up[1]\n",
    "        p_up[1] = 0 \n",
    "    if p_down[0] > img_size[0]:\n",
    "        p_up[0] -= p_down[0] - img_size[0]\n",
    "        p_down[0] = img_size[0]\n",
    "    if p_down[1] > img_size[1]:\n",
    "        p_up[1] -= p_down[1] - img_size[1]\n",
    "        p_down[1] = img_size[1]\n",
    "\n",
    "\n",
    "\n",
    "    return p_up,p_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_castphys = Path(\"D:/TFG_ALEX/castphys_60\")\n",
    "save_folder = Path(\"D:/TFG_ALEX/castphys_crop\")\n",
    "\n",
    "options = {}\n",
    "preprocessing = Video_preprocessing(options)\n",
    "\n",
    "fps = 60\n",
    "\n",
    "ids = [int(patient.split('_')[1]) for patient in glob(\"Patient_*\", root_dir=folder_castphys)]\n",
    "id = ids[0]\n",
    "Patient_path = folder_castphys/ f\"Patient_{id}\"\n",
    "list_videos = glob(\"Q*\",root_dir=Patient_path)# + glob(\"E*\",root_dir=Patient_path)\n",
    "v_name = list_videos[0]\n",
    "img_path = Patient_path / v_name / \"imgs\"\n",
    "\n",
    "video = load_images_bgr(img_path, [])\n",
    "pred_landmarks = preprocessing.landmarks_extraction(video)\n",
    "\n",
    "center = np.min(np.min(pred_landmarks,axis=0),axis=0) + (np.max(np.max(pred_landmarks,axis=0),axis=0)-np.min(np.min(pred_landmarks,axis=0),axis=0))//2\n",
    "p_up,p_down = search_margin_static(center)\n",
    "\n",
    "video_crop = [frm[p_up[1]:p_down[1],p_up[0]:p_down[0],:] for frm in video]\n",
    "\n",
    "video_save = cv2.VideoWriter(str(save_folder / f\"video_{id}_{v_name}_static.avi\"),\n",
    "                             cv2.VideoWriter_fourcc(*'FFV1'),fps,crop_size)\n",
    "for i in range(0,len(video_crop)): #6\n",
    "    video_save.write(video_crop[i])\n",
    "video_save.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
